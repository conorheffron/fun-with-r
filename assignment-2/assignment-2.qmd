---
title: "Assignment 2"
author: "Conor Heffron (23211267)"
format: 
  html:
   embed-resources: true
   code-fold: true
  pdf: default
---

## Task 1: Manipulation

1.  Load the dataset dublin-bikes.txt, save it as a tibble and give meaningful names to the variables related to the weather. 

```{r}
#| code-overflow: wrap
# Load dataset
library(readr)
dublin_bikes <- read_delim("./dublin-bikes-v2.txt", delim = "\t", escape_double = FALSE, col_types = cols(Time = col_character(), `Clontarf - James Larkin Rd` = col_number(), `Clontarf - Pebble Beach Carpark` = col_number(), `Griffith Avenue (Clare Rd Side)` = col_number(), `Griffith Avenue (Lane Side)` = col_number(), `Grove Road Totem` = col_number(), `Richmond Street Cyclists 1` = col_number(), `Richmond Street Cyclists 2` = col_number(), rain = col_number(), temp = col_number(), wdsp = col_number(), clamt = col_number()), trim_ws = TRUE)

# Save as tibble
library(tibble)
db_tib = as_tibble(dublin_bikes)

# Print first 10 rows
head(db_tib, 10)
```

2.  What is the size (number of rows and columns) this dataset? Write some code to check that the variable Time is stored using an appropriate class for a date, and the other variables are numeric, fix them if they aren't.

- 8760 rows and 12 columns

```{r}
# Get dimensions of dublin bikes tibble (8760 rows and 12 columns)
dim(db_tib)
```

```{r}
# Display structure of time column
str(db_tib["Time"])
```

- Time column is character string instead of date/time value

```{r}
# Reformat time variable / column to POSIXct type
tz_chars <- c("T", "Z")
for (ch in tz_chars)
  db_tib["Time"] <- lapply(db_tib["Time"], function(x) gsub(ch, " ", x))
db_tib[['Time']] <- as.POSIXct(db_tib[['Time']], format = "%Y-%m-%d %H:%M:%S")

# Display structure of Dublin bikes tibble
str(db_tib)
```

3.  Convert the variable containing the cloud amount information into an ordered factor. Print the levels and the output of a check to confirm it's ordered. 

```{r}
# clamt cloud amount (okta):
# – 0 oktas represents the complete absence of cloud
# – 1 okta represents a cloud amount of 1 eighth or less, but not zero
# – 7 oktas represents a cloud amount of 7 eighths or more, but not full cloud cover
# – 8 oktas represents full cloud cover with no breaks
# – 9 oktas represents sky obscured by fog or other meteorological phenomena

# Convert the variable containing the cloud amount information into an ordered factor
start <- min(db_tib$clamt)
stop <- max(db_tib$clamt)+1
db_tib$clamt <- factor(db_tib$clamt, levels = start:stop, ordered = TRUE)
```

```{r}
# Print the levels and the output of a check to confirm it's ordered. 
print(levels(db_tib$clamt))
print(paste("db_tib$clamt ordered? ", is.ordered(db_tib$clamt)))
```

4.  Split the information in the column Time into two columns: one containing the date (i.e. date only, no time), and the other the hour. Check that there are 24 hours for each date, and that there are 365 different dates. 

```{r}
db_tib$Date <- as.Date(db_tib$Time) 
db_tib$Hour <- format(as.POSIXct(db_tib$Time), format = "%H:%M:%S") 
```

```{r}
# Load dplyr 
library(dplyr)

# do count by date 
db_tib %>%
  count(Date)
```

```{r}
# Note: There was an NA value for date with count 1 introduced by v2 file

# Omit rows with NA in any column of data frame
db_tib <- na.omit(db_tib)

# do unique count on Date only column 
# (366 and not 355 because data is inclusive of 31st of August in 2022 and 2023)
length(unique(db_tib$Date))
```

5.  Add two columns one containing the day of the week and the other the month. Check that these two columns are ordered factors. 

```{r}
# Extract day of week and month columns from Time variable
db_tib$day_of_week <- weekdays(db_tib$Date)
db_tib$month <- months(db_tib$Date)
```

```{r}
# Convert day of week variable to ordered factor
db_tib$day_of_week <- factor(db_tib$day_of_week, levels = unique(weekdays(db_tib$Date)), ordered = TRUE)
print(paste("db_tib$day_of_week ordered? ", is.ordered(db_tib$day_of_week)))
```

```{r}
# Convert month variable to ordered factor
db_tib$month <- factor(db_tib$month, levels = unique(months(db_tib$Date)), ordered = TRUE)
print(paste("db_tib$month? ", is.ordered(db_tib$month)))
```

```{r}
# Check tibble structure and variable types
str(db_tib)
```

6.  Remove the column Time and use dplyr::relocate() to put the new columns with the date, hour, day of the week, and month as the first four columns of the dataset. 

```{r}
# Drop Time column 
db_tib <- select(db_tib, -Time)
```

```{r}
# relocate Date, Hour, day_of_week, month to the front of tibble
db_tib <- db_tib %>% 
  relocate(Date, Hour, day_of_week, month)

# Sanity check of tibble head data
head(db_tib)
tail(db_tib)
```

## Task 2: Analysis

1.  Use functions from base R to compute which month had in total the highest and the lowest Precipitation Amount. 

```{r}
# base r aggregate function
df_rain <- aggregate(as.numeric(db_tib$rain), by=list(Category=db_tib$month), FUN=sum)
```

```{r}
# Highest precipitation amount
df_rain[which.max(df_rain$x),]
```

```{r}
# Lowest precipitation amount
df_rain[which.min(df_rain$x),]
```

```{r}
# Via dplyr in one shot
df_rain2 <- db_tib %>%
  group_by(month) %>%
  summarise(rain_sum = sum(as.numeric(rain))) %>%
  arrange(desc(rain_sum)) %>%
  filter(row_number()==1 | row_number()==n())

df_rain2
```

2.  Use ggplot2 to create a time series plot of the maximum and minimum daily temperatures. The two time series must be on the same plot.

```{r}
# Add maximum and minimum temperature columns
temps_df <- db_tib %>%
  group_by(day_of_week) %>%
  mutate(max_temp = max(temp), min_temp = min(temp))

temps_df
```

```{r}
# Create and display plot
library(ggplot2)
temps_plot <- ggplot(temps_df, aes(x = min_temp, y = max_temp, color = day_of_week))

temps_plot + geom_point()
```

3.  Check if, according to this dataset, there has been on average more rain during the weekend (Sat-Sun) with respect to weekdays (Mon-Fri). 

```{r}
# Create weekdays vector
weekdays_v <- c("Monday", "Tuesday", "Wednesday", "Thursday", "Friday")

# calculate rainfall for weekdays
rain_weekdays <- db_tib %>% 
  group_by(day_of_week) %>%
  filter(day_of_week %in% weekdays_v) %>%
  summarise(weekdays_rainfall = sum(rain), weekdays_mean_rainfall = mean(rain))

# Initialize weekends vector
weekends_v <- c("Saturday", "Sunday")

# Calculate rainfall for weekends
rain_weekends <- db_tib %>% 
  group_by(day_of_week) %>%
  filter(day_of_week %in% weekends_v) %>%
  summarise(weekends_rainfall = sum(rain), weekends_mean_rainfall = mean(rain))
```

```{r}
# Weekdays rainfall
sum(rain_weekdays$weekdays_rainfall)
```

```{r}
# Weekends rainfall
sum(rain_weekends$weekends_rainfall)
```

```{r}
# Check rain totals by comparing to original data set rain variable
total_rainfall <- sum(db_tib$rain) 
weekdays_rainfall <- sum(rain_weekdays$weekdays_rainfall) 
weekends_rainfall <- sum(rain_weekends$weekends_rainfall)
round(total_rainfall, 2) == round(weekends_rainfall + weekdays_rainfall, 2)

# Check there has been on average more rain during the weekend (Sat-Sun) with 
# respect to weekdays (Mon-Fri)
mean(rain_weekends$weekends_mean_rainfall) > mean(rain_weekdays$weekdays_mean_rainfall)
```

4.  Focus on the data for one month of the year of your choice, create a plot of the daily traﬀic volume in a locations of your choice, and the mode of the Cloud amount each day. Comment on your findings. Notice that there isn't a built-in function to calculate the mode in R. The mode is defined as the most frequently occurring value in the set of observations. 

```{r}
# Map clamt to mode label
db_dec <- db_tib %>%
  filter(month == "December") %>%
  mutate(clamt_mode = case_when(clamt == 0 ~ "absence", 
                        clamt == 1 ~ "1 eight or less", 
                        clamt %in% 2:7 ~ "7 eights or more", 
                        clamt == 8 ~ "full cover", 
                        clamt == 9 ~ "foggy", .default = "NA"))
  
dec_plot <- ggplot(db_dec, aes(y = `Grove Road Totem`, x = day_of_week, color = clamt_mode))
dec_plot + geom_point()
```

## Task 3: Creativity

-   Do something interesting with these data! Create two plots or two tables or one plot and one table showing something we have not discovered above already and outline your findings. 

```{r}
#| label: Creativity
# Get mean, median and standard deviation of 'mean hourly wind speed (kt)'
db_tib %>%
  summarise(mean_wind = mean(wdsp), median_wind = median(wdsp), sd_wind = sd(wdsp))
```

- Mean / Median around 9 and standard deviation is close to 4 overall.
- Lets look closer at this data per month beyond December.

```{r}
# Extract year variable
db_tib$year <- as.numeric(format(db_tib$Date,'%Y'))

# Get mean, median and standard deviation of 'mean hourly wind speed (kt)' per year and month
db_wind <- db_tib %>%
  group_by(year, month) %>%
  summarise(mean_wind = mean(wdsp), median_wind = median(wdsp), sd_wind = sd(wdsp))

# Sort by standard deviation
db_wind %>% arrange(desc(sd_wind))
```

-   Notice that the greatest standard deviation in mean wind speed was in November 2022.
-   However, January 2023 had the highest mean wind speed (only month to hit double digits for abs value).
-   I think this is interesting to note that November 22 was more unpredictable but January was in fact windier on average.

```{r}
library(ggplot2)

# Creat plot for wind aggregattions
ggplot(db_wind, aes(x = month, y = mean_wind, color = sd_wind, size = median_wind)) +
  geom_point()  +
  coord_flip()
```
